{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robi-datathon-19-easy-01",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_ZYxOI1mGNV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Step 01. Install All Dependencies\n",
        "\n",
        "This installs Apache Spark 2.3.3, Java 8, Findspark and most importnantly CSVKit library that makes it easy for Python to work on the given Big Data."
      ]
    },
    {
      "metadata": {
        "id": "MG5jn29qF91X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#OpenJDK Dependencies for Spark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null \n",
        "\n",
        "#Download Apache Spark\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz \n",
        "\n",
        "#Apache Spark and Hadoop Unzip\n",
        "!tar xf spark-2.3.3-bin-hadoop2.7.tgz \n",
        "\n",
        "#FindSpark Install\n",
        "!pip install -q findspark \n",
        "\n",
        "#CSVKit for Handling and Merging CSV Files\n",
        "!pip install -q csvkit "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uE_C9VOSHOKy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 02. Set Environment Variables\n",
        "Set the locations where Spark and Java are installed based on your installation configuration. Double check before you proceed."
      ]
    },
    {
      "metadata": {
        "id": "qrOQoyMmHRPL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.3-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9iRVypEMHiDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 03. Start a Spark Session\n",
        "This basic code will prepare to start a Spark session."
      ]
    },
    {
      "metadata": {
        "id": "vrW7H-rmHmFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('ml-datathon19-easy01').master(\"local[4]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}